 Robertson and WiemerHastings, 2002	<span>[[Text: In this paper we investigate how features of a text discovered via automatic event extraction can be used in both natural language understanding and advice generation in the domain of narrative instruction]]</span>	<span>[[Text: The background application is a fully automated plot analysis agent to improve the writing of students could be used by current narrative tutoring systems (Robertson and WiemerHastings, 2002)]]</span>	<span>[[Text: As shown by participatory design studies, teachers are interested in a plot analysis agent that can give online natural language advice and many students enjoy feedback from an automated agent (Robertson and Cross, 2003)]]</span>
 Robertson and Cross, 2003	<span>[[Text: The background application is a fully automated plot analysis agent to improve the writing of students could be used by current narrative tutoring systems (Robertson and WiemerHastings, 2002)]]</span>	<span>[[Text: As shown by participatory design studies, teachers are interested in a plot analysis agent that can give online natural language advice and many students enjoy feedback from an automated agent (Robertson and Cross, 2003)]]</span>	<span>[[Text: We use automatic event extraction to create a storyindependent automated agent that can both analyze the plot of a story and generate appropriate advice.]]</span>
 Bartlett, 1932	<span>[[Text: This task tests the students ability to both listen and write, while removing from the student the cognitive load needed to generate a new plot]]</span>	<span>[[Text: This task is reminiscent of the well-known “War of the Ghosts” experiment used in psychology for studying memory (Bartlett, 1932) and related to work in ﬁelds such as summarization (Lemaire et al., 2005) and narration (Halpin et al., 2004).]]</span>	
 Lemaire et al., 2005	<span>[[Text: This task tests the students ability to both listen and write, while removing from the student the cognitive load needed to generate a new plot]]</span>	<span>[[Text: This task is reminiscent of the well-known “War of the Ghosts” experiment used in psychology for studying memory (Bartlett, 1932) and related to work in ﬁelds such as summarization (Lemaire et al., 2005) and narration (Halpin et al., 2004).]]</span>	
 Halpin et al., 2004	<span>[[Text: This task tests the students ability to both listen and write, while removing from the student the cognitive load needed to generate a new plot]]</span>	<span>[[Text: This task is reminiscent of the well-known “War of the Ghosts” experiment used in psychology for studying memory (Bartlett, 1932) and related to work in ﬁelds such as summarization (Lemaire et al., 2005) and narration (Halpin et al., 2004).]]</span>	
 Bos et al., 2004	<span>[[Text: Many stories consist of one long run-on sentence]]</span>	<span>[[Text: This leads a traditional parsing system with a direct mapping from the parse tree to a semantic representation to fail to achieve a parse on 35% percent of the stories, and as such could not be used (Bos et al., 2004)]]</span>	<span>[[Text: The stories exhibit frequent use of reported speech and the switching from ﬁrst-person to third-person within a single sentence]]</span>
 Graesser et al., 2000		<span>[[Text: To automatically rate student writing many tutoring systems use Latent Semantic Analysis, a variation on the “bag-of-words” technique that uses dimensionality reduction (Graesser et al., 2000)]]</span>	<span>[[Text: We hypothesize that better results can be achieved using a “representational” account that explicitly represents each event in the plot]]</span>
 Mueller, 2003		<span>[[Text: We represent a story as a sequence of events, p1...ph, represented as a list of predicatearguments, similar to the event calculus (Mueller, 2003)]]</span>	<span>[[Text: Our predicate-argument structure is a minimal subset of ﬁrst-order logic (no quantiﬁers), and so is compatible with case-frame and dependency representations]]</span>
 Kamp and Reyle, 1993	<span>[[Text: Every event has a predicate (function) p that has one or more arguments, n1...na]]</span>	<span>[[Text: In the tradition of Discourse Representation Theory (Kamp and Reyle, 1993), our current predicate argument structure could be converted automatically to ﬁrst order logic by using a default existential quantiﬁcation over the predicates and joining them conjunctively]]</span>	<span>[[Text: Predicate names are often verbs, while their arguments are usually, although not exclusively, nouns or adjectives]]</span>
 Fellbaum, 1998	<span>[[Text: A sentence maps onto one, multiple, or no events]]</span>	<span>[[Text: A unique name and closed-world assumption is enforced, although for purposes of comparing event we compare membership of argument and predicate names in WordNet synsets in addition to exact name matches (Fellbaum, 1998).]]</span>	
 Nenkova and Passonneau, 2004		<span>[[Text: Paralleling work in summarization, it is hypothesized that the quality of a rewritten story can be   deﬁned by the presence or absence of “semantic content units” that are crucial details of the text that may have a variety of syntactic forms (Nenkova and Passonneau, 2004)]]</span>	<span>[[Text: We further hypothesize these can be found in chunks of the text automatically identiﬁed by a chunker, and we can represent these units as predicate-arguments in our event structure]]</span>
 Riloff, 1999	<span>[[Text: We further hypothesize these can be found in chunks of the text automatically identiﬁed by a chunker, and we can represent these units as predicate-arguments in our event structure]]</span>	<span>[[Text: The event structure of each story is automatically extracted using an XMLbased pipeline composed of NLP processing modules, and unlike other story systems, extract full events instead of ﬁlling in a frame of a story script (Riloff, 1999)]]</span>	<span>[[Text: Using the latest version of the Language Technology Text Tokenization Toolkit (Grover et al., 2000), words are tokenized and sentence boundaries detected]]</span>
 Grover et al., 2000	<span>[[Text: The event structure of each story is automatically extracted using an XMLbased pipeline composed of NLP processing modules, and unlike other story systems, extract full events instead of ﬁlling in a frame of a story script (Riloff, 1999)]]</span>	<span>[[Text: Using the latest version of the Language Technology Text Tokenization Toolkit (Grover et al., 2000), words are tokenized and sentence boundaries detected]]</span>	<span>[[Text: Words are given partof-speech tags by a maximum entropy tagger from the toolkit]]</span>
 Baldwin, 1997	<span>[[Text: We do not attempt to obtain a full parse of the sentence due to the highly irregular nature of the sentences]]</span>	<span>[[Text: Pronouns are resolved using a rule-based reimplementation of the CogNIAC algorithm (Baldwin, 1997) and sentences are lemmatized and chunked using the Cass Chunker (Abney, 1995)]]</span>	<span>[[Text: It was felt the chunking method would be the only feasible way to retrieve portions of the sentences that may contain complete “semantic content units” from the ungrammatical and irregular text]]</span>
 Abney, 1995	<span>[[Text: We do not attempt to obtain a full parse of the sentence due to the highly irregular nature of the sentences]]</span>	<span>[[Text: Pronouns are resolved using a rule-based reimplementation of the CogNIAC algorithm (Baldwin, 1997) and sentences are lemmatized and chunked using the Cass Chunker (Abney, 1995)]]</span>	<span>[[Text: It was felt the chunking method would be the only feasible way to retrieve portions of the sentences that may contain complete “semantic content units” from the ungrammatical and irregular text]]</span>
 McNeill et al., 2006	<span>[[Text: It was felt the chunking method would be the only feasible way to retrieve portions of the sentences that may contain complete “semantic content units” from the ungrammatical and irregular text]]</span>	<span>[[Text: The application of a series of rules, mainly mapping verbs to predicate names and nouns to arguments, to the results of the chunker produces events from chunks as described in our previous work (McNeill et al., 2006)]]</span>	<span>[[Text: The accuracy of our rule-set was developed by using the grammatical exemplar stories as a testbed, and a blind judge found they produced 68% interpretable or “sensible” events given the ungrammatical text]]</span>
 Hickmann, 2003	<span>[[Text: Students usually use the present or past tense exclusively throughout the story and events are usually presented in order of occurrence]]</span>	<span>[[Text: An inspection of our corpus showed 3% of stories in our corpus seemed to get the order of events wrong (Hickmann, 2003).]]</span>	
 Deerwester et al., 1990		<span>[[Text: As a baseline system LSA produces a similarity score for each rewritten story by comparing it to the exemplar, this score is used as a distance metric for a k-Nearest Neighbor classiﬁer (Deerwester et al., 1990)]]</span>	<span>[[Text: The parameters for LSA were empirically determined to be a dimensionality of 200 over the semantic space given by the recommended reading list for American 6th graders (Landauer and Dumais, 1997)]]</span>
 Landauer and Dumais, 1997	<span>[[Text: As a baseline system LSA produces a similarity score for each rewritten story by comparing it to the exemplar, this score is used as a distance metric for a k-Nearest Neighbor classiﬁer (Deerwester et al., 1990)]]</span>	<span>[[Text: The parameters for LSA were empirically determined to be a dimensionality of 200 over the semantic space given by the recommended reading list for American 6th graders (Landauer and Dumais, 1997)]]</span>	<span>[[Text: These parameters resulted in the LSA similarity score having a Pearson’s correlation of -.520 with Rater A]]</span>
 Halpin et al., 2004	<span>[[Text: This shows features given by the event   861   Class 1 2 3 4 1 (Excellent) 14 22 0 1 2 (Good) 5 36 0 7 3 (Fair) 3 20 0 2 4 (Poor) 0 11 0 39   Class Precision Recall Excellent .64 .38 Good .40 .75 Fair .00 .00 Poor .80 .78   structure better characterize plot structure than the word distribution]]</span>	<span>[[Text: Unlike previous work, the use of both the plot comparison results and LSA did not improve performance for Naive Bayes, so the results of using Naive Bayes with both are not reported (Halpin et al., 2004)]]</span>	<span>[[Text: The results for the “Adventure” corpus are in general better than the results for the “Thief” corpus]]</span>
 Rose et al., 2002		<span>[[Text: The plot analysis agent is not meant to give the students grades for their stories, but instead use the automatic ratings as an intermediate step to produce advice, like other hybrid tutoring systems (Rose et al., 2002)]]</span>	<span>[[Text: The advice that the agent can generate from the automatic rating classiﬁcation is limited to coarse-grained general advice]]</span>
 Burstein et al., 2003	<span>[[Text: However, by inspecting the results of the plot comparison algorithm, our agent is capable of giving detailed ﬁne-grained speciﬁc advice from the relationships of the events in the story]]</span>	<span>[[Text: One tutoring system resembling ours is the WRITE system, but we differ from it by using event structure to represent the information in the system, instead of using rhetorical features (Burstein et al., 2003)]]</span>	<span>[[Text: In this regards it more closely resembles the physics tutoring system WHY-ATLAS, although we deal with narrative stories of a longer length than physics essays]]</span>
 Rose et al., 2002	<span>[[Text: In this regards it more closely resembles the physics tutoring system WHY-ATLAS, although we deal with narrative stories of a longer length than physics essays]]</span>	<span>[[Text: The WHY-ATLAS physics tutor identiﬁes missing information in the explanations of students using theorem-proving (Rose et al., 2002).]]</span>	
